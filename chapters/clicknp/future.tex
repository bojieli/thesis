%!TEX root=main.tex
\section{Future Work}
\label{clicknp:sec:future}

One challenge for deploying ClickNP in production data centers is 30-second interruption of data plane while FPGA is being reprogrammed. Partial reconfiguration \cite{bourgeault2011alteras} feature of FPGA can be utilized to keep basic packet forwarding functionality while FPGA is being reprogrammed.

On-chip DRAM has relatively low throughput which is insufficient for rule caching and line-rate packet buffering. The problem can be mitigated if host memory can be utilized by kernels. Using existing PCIe streaming interface to access host DRAM incurs high CPU overhead and high latency. In theory the FPGA should be able to access host DRAM via DMA directly, but the implementation of a random-access DMA engine is left for future work.

OpenCL does not provide a way for explicit pipeline control. We cannot control when and where a large combinational logic is split to pipeline stages. Say we have a data handler which loads from a block SRAM, performs a multiplication operation that takes 3 cycles, then stores the result back to it. The OpenCL scheduler will launch the iteration every 3 cycles due to memory dependency. A hardware developer, however, could pipeline the iteration by running three multiplication logics in parallel and re-issuing operations with conflicting addresses -- a well-known technique in superscalar processor and speculative execution.

OpenCL also does not allow explicit specification of an array to be registers or block SRAM. When we need to use a variable to index an array while keeping it as registers instead of block SRAM, we have to use \textit{.repeat} statement to duplicate many copies of a code snippet.

Furthermore, OpenCL cannot figure out independently accessed memory regions and therefore split them into different memory banks. If we use a two-dimensional array \textit{value[DEPTH][WIDTH]} instead of one single-dimensional array \textit{valueN[WIDTH]} per stage in the \textit{IP\_Checksum} example, all accesses to the two-dimensional array would be considered dependent. A similar problem happen to struct members. A symbolic execution engine might be able to recognize such virtual memory dependencies and therefore split the array into distinct memory banks.

Although ClickNP provides abstractions and coding conventions for exploiting spatial and temporal parallelism, software developers still need to learn these abstractions and programming guidelines in order to write fully pipelined elements. Another approach might be recognizing some common coding styles for software programmers bearing the CPU model, and optimize the code automatically. This approach is achievable to some extent, for example, if a loop does not have constant terminating condition, we can still unroll it if the maximum possible iterations can be inferred.
