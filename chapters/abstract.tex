This thesis aims to explore high-performance data center systems based on programmable NICs. Programmable NICs can accelerate not only virtual networks but also network functions, data structures, and operating systems. For this purpose, this thesis implements full-stack acceleration of computing, networking, and memory storage nodes in cloud computing data centers using FPGA programmable NICs.

Firstly, this thesis proposes to accelerate virtual network functions in cloud computing using programmable NICs, and designs and implements the first high-flexibility, high-performance network function processing platform, ClickNP, accelerated by FPGA in commercial servers. To simplify FPGA programming, this thesis designs a C-like ClickNP language and a modular programming model, and develops a series of optimization techniques to fully utilize the massive parallelism of FPGA; implements the ClickNP development toolchain, which can be integrated with various commercial high-level synthesis tools; designs and implements more than 200 network elements based on ClickNP, and uses these elements to build various network functions. Compared with CPU-based software network functions, the throughput of ClickNP is increased by 10 times, and the latency is reduced to 1/10.

Secondly, this thesis proposes to accelerate remote data structure access using programmable NICs. Based on the ClickNP programming framework, this thesis designs and implements a high-performance memory key-value storage system, KV-Direct, which bypasses the CPU on the server side and uses programmable NICs to directly access data structures in remote host memory via PCIe. By extending the memory operation semantics of one-sided RDMA to key-value operation semantics, KV-Direct solves the problem of high communication and synchronization overhead when operating data structures with one-sided RDMA. Taking advantage of the reconfigurable characteristics of FPGA, KV-Direct allows users to implement more complex data structures. Faced with the performance challenges of lower PCIe bandwidth and higher latency between the NIC and host memory, through a series of performance optimizations such as hash tables, memory allocators, out-of-order execution engines, load balancing and caching, and vector operations, KV-Direct achieves 10 times the energy efficiency of CPU and microsecond-level latency, and is the first general-purpose key-value storage system with a single-machine performance reaching 1 billion operations per second.

The content you provided is already in English and it is written in an academic style. As per your instructions, I will keep it as-is. Here is the content:

Finally, this thesis proposes to provide socket communication primitives for applications by combining programmable NICs and user-mode runtime libraries, thereby bypassing the operating system kernel. This thesis designs and implements a user-mode socket system, SocksDirect, which is fully compatible with existing applications, can achieve near-hardware-limit throughput and latency, has scalable multi-core performance, and maintains high performance under high-concurrent loads. Intra-host and inter-host communications are implemented using shared memory and RDMA, respectively. To support a high number of concurrent connections, this thesis implements an RDMA programmable NIC based on KV-Direct. By eliminating a series of overheads such as inter-thread synchronization, buffer management, large data copying, process wakeup, etc., SocksDirect improves the throughput by 7 to 20 times compared to Linux, reduces the latency to 1/17 to 1/35, and reduces the HTTP latency of the web server to 1/5.5.

\keywords{Data Center; Programmable NIC; Field Programmable Gate Array; Network Function Virtualization; Key-Value Storage; Network Protocol Stack}
\end{enabstract}

This thesis aims to explore high performance data center systems with programmable NICs.
Besides accelerating network virtualization, programmable NICs can also accelerate network functions, data structures and operating systems.
For this purpose, this thesis proposes a system that uses FPGA-based programmable NIC for full stack acceleration of compute, network and in-memory storage nodes in cloud data centers.

First, this thesis proposes to accelerate virtualized network functions in the cloud with programmable NICs. This thesis proposes ClickNP, the first FPGA accelerated network function processing platform on commodity servers with high flexibility and high performance.
To simplify FPGA programming, this thesis designs a C-like ClickNP language and a modular programming model, and also develops optimization techniques to fully exploit the massive parallelism inside FPGA.
The ClickNP tool-chain integrates with multiple commercial high-level synthesis tools.
Based on ClickNP, this thesis designs and implements more than 200 network elements, and constructs various network functions using the elements.
Compared to CPU-based software network functions, ClickNP improves throughput by 10 times and reduces latency to 1/10.

Secondly, this thesis proposes the acceleration of remote data structure access using programmable NICs. The thesis designs and implements KV-Direct, a high-performance in-memory key-value storage system based on the ClickNP programming framework. KV-Direct bypasses the server-side CPU and uses programmable NICs to directly access data structures in the remote host memory via PCIe. KV-Direct extends the memory semantics of one-sided RDMA to key-value semantics, thereby avoiding communication and synchronization overheads in data structure operations. KV-Direct further leverages the reconfigurability of FPGA to enable users to implement more complex data structures. To address the performance challenge of limited PCIe bandwidth and high latency between NIC and host memory, this thesis designs a series of optimizations including a hash table, memory allocator, out-of-order execution engine, load balancing, caching, and vector operations. KV-Direct achieves a power efficiency ten times greater than that of a CPU and microsecond-scale latency. KV-Direct is the first general key-value storage system to achieve a performance of 1 billion operations per second on a single server.

Finally, this dissertation proposes a co-design of programmable NICs and user-space libraries to provide kernel-bypass socket communication primitives for applications. The dissertation designs and implements SocksDirect, a user-space socket system that is fully compatible with existing applications, achieves throughput and latency that are close to hardware limits, has scalable performance for multi-cores, and maintains high performance with many concurrent connections. SocksDirect uses shared memory and RDMA for intra-host and inter-host communication, respectively. To support many concurrent connections, SocksDirect implements an RDMA programmable NIC based on KV-Direct. SocksDirect further removes overheads such as thread synchronization, buffer management, large payload copying, and process wakeup. Compared to Linux, SocksDirect improves throughput by 7 to 20 times, reduces latency to 1/17 to 1/35, and reduces the HTTP latency of web servers to 1/5.5.

The content you provided is already in English, so according to your instructions, I will keep it as-is:

\enkeywords{Data Center; Programmable NIC; FPGA; Network Function Virtualization; Key-Value Store; Networking Stack}
\end{enabstract}
